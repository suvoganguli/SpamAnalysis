{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e21d1a-2270-4b19-87aa-229896e5e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing text files\n",
    "directory = \"enron1/spam\"\n",
    "\n",
    "# List to store texts\n",
    "emails = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "        email = file.read()  # Read the content of the file\n",
    "        emails.append(email)  # Append the text to the list\n",
    "        labels.append('spam')\n",
    "\n",
    "# Directory containing text files\n",
    "directory = \"enron1/spam\"\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "        email = file.read()  # Read the content of the file\n",
    "        emails.append(email)  # Append the text to the list\n",
    "        labels.append('ham')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93bb121e-5b56-42c2-b807-c494f34c41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory containing text files\n",
    "directory = \"enron2/spam\"\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "        email = file.read()  # Read the content of the file\n",
    "        emails.append(email)  # Append the text to the list\n",
    "        labels.append('spam')\n",
    "\n",
    "# Directory containing text files\n",
    "directory = \"enron2/spam\"\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "        email = file.read()  # Read the content of the file\n",
    "        emails.append(email)  # Append the text to the list\n",
    "        labels.append('ham')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa91dda-dbb5-4c47-b050-58e11ea7bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory containing text files\n",
    "directory = \"enron3/spam\"\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "        email = file.read()  # Read the content of the file\n",
    "        emails.append(email)  # Append the text to the list\n",
    "        labels.append('spam')\n",
    "\n",
    "# Directory containing text files\n",
    "directory = \"enron3/spam\"\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "        email = file.read()  # Read the content of the file\n",
    "        emails.append(email)  # Append the text to the list\n",
    "        labels.append('ham')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24398661-7610-4e15-a672-288ef16f59ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory containing text files\n",
    "directory = \"enron4/spam\"\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "        email = file.read()  # Read the content of the file\n",
    "        emails.append(email)  # Append the text to the list\n",
    "        labels.append('spam')\n",
    "\n",
    "# Directory containing text files\n",
    "directory = \"enron4/spam\"\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "        email = file.read()  # Read the content of the file\n",
    "        emails.append(email)  # Append the text to the list\n",
    "        labels.append('ham')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142b23e2-a40d-4397-bb60-de8bda17f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory containing text files\n",
    "directory = \"enron5/spam\"\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "        email = file.read()  # Read the content of the file\n",
    "        emails.append(email)  # Append the text to the list\n",
    "        labels.append('spam')\n",
    "\n",
    "# Directory containing text files\n",
    "directory = \"enron5/spam\"\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "        email = file.read()  # Read the content of the file\n",
    "        emails.append(email)  # Append the text to the list\n",
    "        labels.append('ham')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "387ae687-4348-4e05-945a-80d48133c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory containing text files\n",
    "directory = \"enron6/spam\"\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "        email = file.read()  # Read the content of the file\n",
    "        emails.append(email)  # Append the text to the list\n",
    "        labels.append('spam')\n",
    "\n",
    "# Directory containing text files\n",
    "directory = \"enron6/spam\"\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    with open(os.path.join(directory, filename), \"r\", encoding=\"latin-1\") as file:\n",
    "        email = file.read()  # Read the content of the file\n",
    "        emails.append(email)  # Append the text to the list\n",
    "        labels.append('ham')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c65f52-92a8-4a61-abce-4ff9e65eac28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Email Label\n",
      "0      Subject: what up , , your cam babe\\nwhat are y...  spam\n",
      "1      Subject: want to make more money ?\\norder conf...  spam\n",
      "2      Subject: food for thoughts\\n[\\njoin now - take...  spam\n",
      "3      Subject: miningnews . net newsletter - tuesday...  spam\n",
      "4      Subject: your pharmacy ta\\nwould you want chea...  spam\n",
      "...                                                  ...   ...\n",
      "37329  Subject: fw : bigger cock ( cialis )\\ncall us ...   ham\n",
      "37330  Subject: feel great any time of the day summer...   ham\n",
      "37331  Subject: do you want a watch ?\\nhttp : / / inl...   ham\n",
      "37332  Subject: re ; your valium refill is ready\\nhi ...   ham\n",
      "37333  Subject: unlicensed installation found on your...   ham\n",
      "\n",
      "[37334 rows x 2 columns]\n",
      "0        Subject: what up , , your cam babe\\nwhat are y...\n",
      "1        Subject: want to make more money ?\\norder conf...\n",
      "2        Subject: food for thoughts\\n[\\njoin now - take...\n",
      "3        Subject: miningnews . net newsletter - tuesday...\n",
      "4        Subject: your pharmacy ta\\nwould you want chea...\n",
      "                               ...                        \n",
      "37329    Subject: fw : bigger cock ( cialis )\\ncall us ...\n",
      "37330    Subject: feel great any time of the day summer...\n",
      "37331    Subject: do you want a watch ?\\nhttp : / / inl...\n",
      "37332    Subject: re ; your valium refill is ready\\nhi ...\n",
      "37333    Subject: unlicensed installation found on your...\n",
      "Name: Email, Length: 37334, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the texts\n",
    "df = pd.DataFrame({\"Email\": emails, \"Label\": labels})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "X = df['Email']\n",
    "y = df['Label']\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d722b4-ff2d-4e41-a41e-14ee6e1b318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = nb_classifier.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Example \n",
    "\n",
    "# new_emails = [\"New email text 1\", \"New email text 2\", ...]\n",
    "# new_emails_vec = vectorizer.transform(new_emails)\n",
    "# predictions = nb_classifier.predict(new_emails_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29cc6c21-9a32-41e8-9ff6-c7dfa81e5ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14664523905182805\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.15      0.15      0.15      3717\n",
      "        spam       0.14      0.14      0.14      3750\n",
      "\n",
      "    accuracy                           0.15      7467\n",
      "   macro avg       0.15      0.15      0.15      7467\n",
      "weighted avg       0.15      0.15      0.15      7467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming you have your data loaded into X (email texts) and y (labels)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(max_iter = 10000)\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb47097f-5f19-43e4-baea-b6d9f23d4834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4021695460024106\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.44      0.70      0.54      3717\n",
      "        spam       0.26      0.11      0.15      3750\n",
      "\n",
      "    accuracy                           0.40      7467\n",
      "   macro avg       0.35      0.40      0.34      7467\n",
      "weighted avg       0.35      0.40      0.34      7467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming you have your data loaded into X (text) and y (labels)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm = SVC(kernel='rbf')\n",
    "svm.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm.predict(X_test_vec)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a7cae6-c574-48c1-9362-fe94f514b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# 5. Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_vec.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 6. Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 7. Train the model\n",
    "model.fit(X_train_vec, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# 8. Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test_vec, y_test)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# 9. Make predictions (if needed)\n",
    "# y_pred = model.predict(X_test_vec)\n",
    "# Use y_pred for further analysis or evaluation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d531a8db-360f-4759-9ba8-40f9f3603d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
